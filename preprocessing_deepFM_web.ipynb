{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asas4\\anaconda3\\envs\\rmd_sys\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "Namespace(lr=0.001, epochs=2, device='cuda', patience=10, batch_size=32)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import warnings\n",
    "from keybert import KeyBERT\n",
    "from Module.trainer import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:35.017999Z",
     "start_time": "2025-02-16T09:27:02.020789800Z"
    }
   },
   "id": "359485240504f4e4",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35be64a3390a6e1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\asas4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:40.843985200Z",
     "start_time": "2025-02-16T09:27:35.012722100Z"
    }
   },
   "id": "ff49b5684c1a2082",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv('Database/article_info.csv').fillna('NAN')\n",
    "view_log_df = pd.read_csv('Database/view_log.csv').drop_duplicates().reset_index(drop=True)\n",
    "view_log_df = pd.concat([view_log_df, pd.DataFrame([{'userID': 'USER_9999', 'articleID': 'ARTICLE_0001'}])],\n",
    "                        ignore_index=True)\n",
    "df_0 = pd.read_parquet('File/view_log_df.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:46.650431400Z",
     "start_time": "2025-02-16T09:27:40.847023900Z"
    }
   },
   "id": "a79097a2033123b4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model=model)\n",
    "keywords = kw_model.extract_keywords(docs=data.Title, top_n=1)\n",
    "keywords[1849] = [('.', 0.0)]\n",
    "data[\"Content_Keyword\"] = [pair[0] for sub_lst in keywords for pair in sub_lst]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:55.425017700Z",
     "start_time": "2025-02-16T09:27:46.644557500Z"
    }
   },
   "id": "4cb5a6ccc925bd0b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_1 = df_0.merge(data, on=\"articleID\", how=\"left\")\n",
    "\n",
    "# NumPy 벡터화 연산으로 변환\n",
    "cosine_sim_array = np.vstack(df_1['cosine_sim'].values)\n",
    "cosine_sim2_array = np.vstack(df_1['cosine_sim2'].values)\n",
    "\n",
    "# 벡터를 데이터프레임으로 변환\n",
    "cosine_sim_expanded = pd.DataFrame(cosine_sim_array,\n",
    "                                   columns=[f'cosine_sim_{i}' for i in range(cosine_sim_array.shape[1])])\n",
    "cosine_sim2_expanded = pd.DataFrame(cosine_sim2_array,\n",
    "                                    columns=[f'cosine_sim2_{i}' for i in range(cosine_sim2_array.shape[1])])\n",
    "\n",
    "# cosin_sim 나중에 쓸지도 몰라 이어 붙임.\n",
    "df_1 = pd.concat([df_1, cosine_sim_expanded], axis=1).dropna()\n",
    "\n",
    "input_lst = ['userID_x', 'articleID', 'userRegion_x', 'userCountry_x', 'Format', 'Language', 'userID_y',\n",
    "             'userCountry_y', 'userRegion_y']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:56.415022100Z",
     "start_time": "2025-02-16T09:27:55.430652600Z"
    }
   },
   "id": "38ef87b7fe6ea4c4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_2 = df_1[input_lst].dropna()\n",
    "\n",
    "encoder_dict = {}\n",
    "\n",
    "for col in ['userID_x', 'articleID', 'userRegion_x', 'userCountry_x', 'Format', 'Language']:\n",
    "    encoder_dict[col] = LabelEncoder()\n",
    "    df_2[col] = encoder_dict[col].fit_transform(df_2[col])\n",
    "\n",
    "# 새로운 값이 존재하면 기존 encoder에 추가\n",
    "for col in ['userID_y', 'userCountry_y', 'userRegion_y']:\n",
    "    parent_col = col[:-1] + 'x'\n",
    "\n",
    "    # 기존 encoder 불러오기\n",
    "    encoder = encoder_dict[parent_col]\n",
    "\n",
    "    # 기존에 없는 새로운 값 찾기\n",
    "    unseen_values = set(df_2[col].unique()) - set(encoder.classes_)\n",
    "\n",
    "    if unseen_values:\n",
    "        # 새로운 값 추가 후 재훈련\n",
    "        new_classes = np.append(encoder.classes_, list(unseen_values))\n",
    "        encoder.classes_ = new_classes  # 직접 classes_ 속성 업데이트\n",
    "\n",
    "    # 변환 적용\n",
    "    df_2[col] = encoder.transform(df_2[col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:56.503561400Z",
     "start_time": "2025-02-16T09:27:56.417501400Z"
    }
   },
   "id": "cc9c36dd76c9be12",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_3 = df_2.copy()\n",
    "df_3['Ground Truth'] = 1\n",
    "\n",
    "# userID 별 등장 횟수 계산\n",
    "user_counts = df_3['userID_x'].value_counts().sort_values()\n",
    "\n",
    "# 부정 샘플을 저장할 리스트\n",
    "negative_samples = []\n",
    "\n",
    "for user_id, count in user_counts.items():\n",
    "    # 현재 userID 제외한 데이터에서 랜덤 샘플링\n",
    "    candidate_samples = df_3[df_3['userID_x'] != user_id].sample(n=min(count, len(df_3) - count), replace=False)\n",
    "    candidate_samples['userID_x'] = user_id\n",
    "    # 부정 샘플의 label을 0으로 설정\n",
    "    candidate_samples['Ground Truth'] = 0\n",
    "\n",
    "    # 부정 샘플 리스트에 추가\n",
    "    negative_samples.append(candidate_samples)\n",
    "\n",
    "# 부정 샘플 데이터프레임 생성\n",
    "negative_df = pd.concat(negative_samples, ignore_index=True)\n",
    "\n",
    "# userID_x 기준 정렬\n",
    "negative_df = negative_df.sort_values(by='userID_x').reset_index(drop=True)\n",
    "\n",
    "# 기존 데이터와 부정 샘플 데이터 결합\n",
    "df_3 = pd.concat([df_3, negative_df]).reset_index(drop=True)\n",
    "df_3 = df_3.sort_values(by=['userID_x', 'Ground Truth']).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:59.592815200Z",
     "start_time": "2025-02-16T09:27:56.508002500Z"
    }
   },
   "id": "6b79951a88fd6f2a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_4, test = train_test_split(df_3, test_size=0.1, random_state=42)\n",
    "df_4.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "x = df_4.drop(columns='Ground Truth')\n",
    "y = df_4['Ground Truth']\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "x_test = test.drop(columns='Ground Truth')\n",
    "y_test = test['Ground Truth']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:27:59.611166800Z",
     "start_time": "2025-02-16T09:27:59.593815700Z"
    }
   },
   "id": "9921205798ac6527",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 데이터 저장 경로\n",
    "train_val_test_split = {\n",
    "    \"x_train\": x_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"x_val\": x_val,\n",
    "    \"y_val\": y_val,\n",
    "    \"x_test\": x_test,\n",
    "    \"y_test\": y_test\n",
    "}\n",
    "\n",
    "# pickle 파일로 저장\n",
    "file_path = \"Database/train_val_test.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(train_val_test_split, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-02T05:00:11.548493100Z",
     "start_time": "2025-02-02T05:00:11.539318900Z"
    }
   },
   "id": "3193f504ccef7c98",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "      userID_x  articleID  userRegion_x  userCountry_x  Format  Language  \\\n0          731       1054            49              2       0         0   \n1          566        728            49              2       1         0   \n2          679       2546            49              2       0         0   \n3         1334        668            49              2       0         0   \n4          597       1472            25              2       0         4   \n...        ...        ...           ...            ...     ...       ...   \n6361       307       1726            25              2       0         0   \n6362       335       2857            49              2       0         0   \n6363       355       1863            49              2       0         0   \n6364       109       1542            49              2       0         0   \n6365       325       1418            49              2       0         4   \n\n      userID_y  userCountry_y  userRegion_y  \n0          251             21            57  \n1          416             21            57  \n2          176             21            57  \n3         1298             21            57  \n4         1185             21            57  \n...        ...            ...           ...  \n6361      1082             21            57  \n6362       335              2            49  \n6363       400             21            57  \n6364      1298             21            57  \n6365       674             21            57  \n\n[6366 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID_x</th>\n      <th>articleID</th>\n      <th>userRegion_x</th>\n      <th>userCountry_x</th>\n      <th>Format</th>\n      <th>Language</th>\n      <th>userID_y</th>\n      <th>userCountry_y</th>\n      <th>userRegion_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>731</td>\n      <td>1054</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>251</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>566</td>\n      <td>728</td>\n      <td>49</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>416</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>679</td>\n      <td>2546</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>176</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1334</td>\n      <td>668</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1298</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>597</td>\n      <td>1472</td>\n      <td>25</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1185</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6361</th>\n      <td>307</td>\n      <td>1726</td>\n      <td>25</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1082</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>6362</th>\n      <td>335</td>\n      <td>2857</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>335</td>\n      <td>2</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>6363</th>\n      <td>355</td>\n      <td>1863</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>400</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>6364</th>\n      <td>109</td>\n      <td>1542</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1298</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>6365</th>\n      <td>325</td>\n      <td>1418</td>\n      <td>49</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>674</td>\n      <td>21</td>\n      <td>57</td>\n    </tr>\n  </tbody>\n</table>\n<p>6366 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-16T09:59:38.263740800Z",
     "start_time": "2025-02-16T09:59:37.765556400Z"
    }
   },
   "id": "4dc39b56cb2d221e",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
